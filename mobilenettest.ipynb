{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58a0eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\envs\\yolo\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 지정된 프로시저를 찾을 수 없습니다'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# 셀 1: 필수 라이브러리 불러오기\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9715b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelTrafficLightDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.label_cols = ['label_red', 'label_yellow', 'label_green', 'label_left']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(self.data.at[idx, 'filename']).strip()\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"[{idx}] 이미지 파일 없음: {img_path}\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        labels = torch.tensor(self.data.loc[idx, self.label_cols].values.astype(float), dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0d6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 3: 전처리 정의\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff3a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 4: 절대경로 지정\n",
    "base_dir = r\"C:\\Users\\LENOVO\\Documents\\yolo\\mobilenetdata\"  # 여기를 사용자의 실제 절대경로로 변경하세요\n",
    "\n",
    "train_csv_path = os.path.join(base_dir, \"train.csv\")\n",
    "val_csv_path = os.path.join(base_dir, \"val.csv\")\n",
    "train_img_dir = os.path.join(base_dir, \"train_images\")\n",
    "val_img_dir = os.path.join(base_dir, \"val_images\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681770c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 5: 데이터로더 정의\n",
    "train_dataset = MultiLabelTrafficLightDataset(train_csv_path, train_img_dir, transform=train_transform)\n",
    "val_dataset = MultiLabelTrafficLightDataset(val_csv_path, val_img_dir, transform=val_transform)\n",
    "    \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5651bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 6: 모델 불러오기 및 수정\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = MobileNet_V2_Weights.DEFAULT\n",
    "model = mobilenet_v2(weights=weights)\n",
    "model.classifier[1] = nn.Linear(model.last_channel, 4)  # 클래스 수 4개로 변경\n",
    "model = model.to(device)  # GPU 또는 CPU로 모델 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abef5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = weights.transforms()\n",
    "val_transform = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5606e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 7: 손실함수 및 옵티마이저 정의\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39f9e929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6891\n",
      "Epoch 2/10, Loss: 0.6809\n",
      "Epoch 3/10, Loss: 0.6695\n",
      "Epoch 4/10, Loss: 0.6478\n",
      "Epoch 5/10, Loss: 0.6341\n",
      "Epoch 6/10, Loss: 0.6320\n",
      "Epoch 7/10, Loss: 0.6124\n",
      "Epoch 8/10, Loss: 0.5993\n",
      "Epoch 9/10, Loss: 0.5876\n",
      "Epoch 10/10, Loss: 0.5637\n"
     ]
    }
   ],
   "source": [
    "# 셀 8: 학습 루프\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "336f2b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score: 0.1667\n"
     ]
    }
   ],
   "source": [
    "# 셀 9: 검증 및 F1-score 측정\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.sigmoid(outputs).cpu()\n",
    "        preds = (probs > 0.5).int()\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f\"Validation F1 Score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 10: 모델 저장\n",
    "torch.save(model.state_dict(), os.path.join(base_dir, \"mobilenetv2_trafficlight_multilabel.pth\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
